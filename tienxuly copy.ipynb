{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/product_df.csv')\n",
    "df = df[['Star Rating', 'Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment   Sentiment\n",
      "0            4                      Điện thoại này dùng rất thích    tích cực\n",
      "1            4                               sử dụng thấy cũng ok    tích cực\n",
      "2            2                      Bảo hành ít quá, chỉ 12 tháng    tiêu cực\n",
      "3            5                             Sản phẩm mượt, chạy êm    tích cực\n",
      "4            3  Cho mình hỏi muốn khởi động lại máy hay tắt ng...  trung tính\n"
     ]
    }
   ],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 'tiêu cực'\n",
    "    elif rating == 3:\n",
    "        return 'trung tính'\n",
    "    elif rating in [4, 5]:\n",
    "        return 'tích cực'\n",
    "    else:\n",
    "        return 'không rõ'  # Nếu có xếp hạng nằm ngoài khoảng 1-5\n",
    "\n",
    "# Gắn nhãn cảm xúc cho mỗi đánh giá\n",
    "df['Sentiment'] = df['Star Rating'].apply(label_sentiment)\n",
    "\n",
    "# Hiển thị 5 hàng đầu tiên của dataframe với cột sentiment mới\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Rating    0\n",
      "Comment        0\n",
      "Sentiment      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra và loại bỏ giá trị khuyết thiếu\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các dòng dữ liệu trùng lặp trong cột 'Comment':\n",
      "      Star Rating                                   Comment Sentiment\n",
      "48              4                                   Rất tốt  tích cực\n",
      "76              5                                    Rất ok  tích cực\n",
      "107             2                             pin tụt nhanh  tiêu cực\n",
      "135             5                              sản phẩm tốt  tích cực\n",
      "173             2                             hao pin nhanh  tiêu cực\n",
      "177             5                              sản phẩm tốt  tích cực\n",
      "181             5                                    Rất ok  tích cực\n",
      "183             5                              sản phẩm tốt  tích cực\n",
      "192             5                               sản phẩm ok  tích cực\n",
      "205             5                               máy dùng ok  tích cực\n",
      "225             4                                       Tốt  tích cực\n",
      "227             5                               sản phẩm ok  tích cực\n",
      "237             5                               máy dùng ok  tích cực\n",
      "250             5                              sản phẩm tốt  tích cực\n",
      "426             4                              máy dùng tốt  tích cực\n",
      "435             5                                   Rất tốt  tích cực\n",
      "461             4                                       Tốt  tích cực\n",
      "516             5                                       Tốt  tích cực\n",
      "526             4                                       Tốt  tích cực\n",
      "529             4                                    Tạm ổn  tích cực\n",
      "547             5                              Sản phẩm tốt  tích cực\n",
      "549             5                                  Cũng tốt  tích cực\n",
      "568             4                                  Hài lòng  tích cực\n",
      "570             5                          Máy dùng rất tốt  tích cực\n",
      "592             5                                       Tốt  tích cực\n",
      "647             5                                   Rất tốt  tích cực\n",
      "683             5                                       Tốt  tích cực\n",
      "744             5                                       Tốt  tích cực\n",
      "976             5                          Máy dùng rất tốt  tích cực\n",
      "982             4                                 Tuyệt vời  tích cực\n",
      "1153            5                                      Tốt.  tích cực\n",
      "1160            5                          Máy sử dụng tốt.  tích cực\n",
      "1163            5                                      Tốt.  tích cực\n",
      "1237            5                                 Khá được.  tích cực\n",
      "1244            4                                     Được.  tích cực\n",
      "1260            5                             Rất hài lòng.  tích cực\n",
      "1271            4                     Hiện tại sử dụng tốt.  tích cực\n",
      "1272            5                         Tôi rất hài lòng.  tích cực\n",
      "1273            4  Sản phẩm được. Hợp túi tiền dùng tạm ổn.  tích cực\n",
      "1280            5                             Rất hài lòng.  tích cực\n",
      "1283            5                                     Được.  tích cực\n",
      "1311            5                             Dùng rất tốt.  tích cực\n",
      "1328            5                  Điện thoại dùng rất tốt.  tích cực\n",
      "1338            4                             Sản phẩm tốt.  tích cực\n",
      "1409            5                                     Được.  tích cực\n",
      "1443            4                                 Dùng tốt.  tích cực\n",
      "Shape after dropping duplicates: (1498, 3)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra và loại bỏ dữ liệu trùng lặp\n",
    "duplicate_comments = df[df.duplicated(['Comment'])]\n",
    "print(\"Các dòng dữ liệu trùng lặp trong cột 'Comment':\")\n",
    "print(duplicate_comments)\n",
    "df = df.drop_duplicates(['Comment'])\n",
    "print(\"Shape after dropping duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment   Sentiment\n",
      "0            4                      điện thoại này dùng rất thích    tích cực\n",
      "1            4                               sử dụng thấy cũng ok    tích cực\n",
      "2            2                       bảo hành ít quá chỉ 12 tháng    tiêu cực\n",
      "3            5                              sản phẩm mượt chạy êm    tích cực\n",
      "4            3  cho mình hỏi muốn khởi động lại máy hay tắt ng...  trung tính\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa và làm sạch văn bản\n",
    "def remove_special_characters(text):\n",
    "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ cái, số, và các dấu câu\n",
    "    return re.sub(r'[^a-zA-ZÀ-ỹà-ỹ0-9\\s]', '', text)\n",
    "\n",
    "def to_lowercase(text):\n",
    "    # Chuyển đổi văn bản về chữ thường\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_special_characters(text)\n",
    "    text = to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(normalize_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số từ duy nhất: 2386\n",
      "Các từ và tần suất xuất hiện:\n",
      "máy: 715\n",
      "không: 659\n",
      "dùng: 593\n",
      "mua: 472\n",
      "được: 422\n",
      "rất: 409\n",
      "pin: 347\n",
      "tốt: 338\n",
      "mình: 322\n",
      "thì: 319\n"
     ]
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "# Function to tokenize and build vocab using underthesea\n",
    "def tokenize_and_build_vocab_vietnamese(comment):\n",
    "    tokens = word_tokenize(comment, format=\"text\")\n",
    "    return tokens.split()\n",
    "\n",
    "# Tokenize comments and build vocabulary\n",
    "tokenized_comments = df['Comment'].apply(tokenize_and_build_vocab_vietnamese)\n",
    "all_tokens = [token for sublist in tokenized_comments for token in sublist]\n",
    "vocab = FreqDist(all_tokens)\n",
    "\n",
    "# Build vocab_list from vocab\n",
    "vocab_list = list(vocab.keys())\n",
    "\n",
    "print(\"Tổng số từ duy nhất:\", len(vocab_list))\n",
    "print(\"Các từ và tần suất xuất hiện:\")\n",
    "for word, frequency in vocab.most_common(10):  # Print only top 10 words\n",
    "    print(f\"{word}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_with_labels(path):\n",
    "    # Hàm này có thể được sửa đổi để phù hợp với định dạng dữ liệu cụ thể của bạn\n",
    "    # Đọc dữ liệu và nhãn từ tập tin ở đường dẫn path\n",
    "    reviews = []  # Danh sách các đánh giá\n",
    "    labels = []   # Danh sách các nhãn tương ứng\n",
    "\n",
    "    # Code đọc dữ liệu từ file ở đây và lưu vào reviews và labels\n",
    "\n",
    "    return reviews, labels\n",
    "\n",
    "reviews, labels = read_data_with_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chuẩn bị dữ liệu đầu vào cho Word2Vec\n",
    "input_gensim = [review.split() for review in reviews]\n",
    "\n",
    "# Khởi tạo mô hình Word2Vec\n",
    "model = Word2Vec(vector_size=128, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Chuyển đổi vocab_list thành một từ điển với tần suất mặc định\n",
    "word_freq = {word: 1 for word in vocab_list}\n",
    "\n",
    "# Thiết lập danh sách từ vựng và vector của từng từ\n",
    "model.build_vocab_from_freq(word_freq)\n",
    "\n",
    "# Thiết lập các tham số cho mô hình\n",
    "model.train(input_gensim, total_examples=len(input_gensim), epochs=10)\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(\"word.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Word2Vec model\n",
    "model_embedding = Word2Vec.load('word.model')\n",
    "\n",
    "max_seq = 200\n",
    "embedding_size = 128\n",
    "\n",
    "def comment_embedding(comment):\n",
    "    matrix = np.zeros((max_seq, embedding_size))\n",
    "    words = comment.split()\n",
    "    lencmt = len(words)\n",
    "\n",
    "    for i in range(max_seq):\n",
    "        indexword = i % lencmt\n",
    "        if (max_seq - i < lencmt):\n",
    "            break\n",
    "        if words[indexword] in model_embedding.wv:\n",
    "            matrix[i] = model_embedding.wv[words[indexword]]\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã hóa one-hot cho label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [0, 1, 0]\n",
      "1       [0, 1, 0]\n",
      "2       [0, 0, 1]\n",
      "3       [0, 1, 0]\n",
      "4       [1, 0, 0]\n",
      "          ...    \n",
      "1539    [0, 0, 1]\n",
      "1540    [1, 0, 0]\n",
      "1541    [0, 0, 1]\n",
      "1542    [0, 1, 0]\n",
      "1543    [0, 1, 0]\n",
      "Name: Sentiment, Length: 1498, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Mã hóa sentiment thành các vectơ theo yêu cầu\n",
    "sentiment_mapping = {\n",
    "    'trung tính': [1, 0, 0],\n",
    "    'tích cực': [0, 1, 0],\n",
    "    'tiêu cực': [0, 0, 1]\n",
    "}\n",
    "\n",
    "# Ánh xạ các nhãn sentiment sang vectơ mã hóa\n",
    "df['Sentiment'] = df['Sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "print(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1498/1498 [00:01<00:00, 1083.88it/s]\n",
      "100%|██████████| 1498/1498 [00:00<00:00, 21870.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming df['Comment'] contains your preprocessed comments\n",
    "pre_reviews = df['Comment'].tolist()  # Convert DataFrame column to list if needed\n",
    "labels = df['Sentiment'].tolist()  # Assuming you have a 'Sentiment' column with labels\n",
    "\n",
    "train_data = []\n",
    "label_data = []\n",
    "\n",
    "for x in tqdm(pre_reviews):\n",
    "    train_data.append(comment_embedding(x))\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "for y in tqdm(labels):\n",
    "    label_ = np.zeros(3)\n",
    "    try:\n",
    "        label_[int(y)] = 1\n",
    "    except:\n",
    "        label_[0] = 1\n",
    "    label_data.append(label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "sequence_length = 200\n",
    "embedding_size = 128\n",
    "num_classes = 3\n",
    "filter_sizes = 3\n",
    "num_filters = 150\n",
    "epochs = 50\n",
    "batch_size = 30\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,750</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)    │        \u001b[38;5;34m57,750\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m150\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m19,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,465</span> (302.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,465\u001b[0m (302.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,465</span> (302.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,465\u001b[0m (302.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define your model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(num_filters, (filter_sizes, embedding_size),\n",
    "                        padding='valid',\n",
    "                        input_shape=(sequence_length, embedding_size, 1), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(198, 1)))\n",
    "model.add(layers.Dropout(dropout_rate))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model with the Adam optimizer\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 2.7056e-06 - val_accuracy: 1.0000 - val_loss: 6.9371e-07\n",
      "Epoch 2/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 3.0202e-06 - val_accuracy: 1.0000 - val_loss: 6.4991e-07\n",
      "Epoch 3/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 3.4141e-06 - val_accuracy: 1.0000 - val_loss: 6.0658e-07\n",
      "Epoch 4/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.6357e-06 - val_accuracy: 1.0000 - val_loss: 5.5296e-07\n",
      "Epoch 5/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.1173e-06 - val_accuracy: 1.0000 - val_loss: 5.1586e-07\n",
      "Epoch 6/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.9549e-06 - val_accuracy: 1.0000 - val_loss: 4.8976e-07\n",
      "Epoch 7/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.4484e-06 - val_accuracy: 1.0000 - val_loss: 4.6032e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 3.2221e-06 - val_accuracy: 1.0000 - val_loss: 4.2776e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 2.5016e-06 - val_accuracy: 1.0000 - val_loss: 3.9641e-07\n",
      "Epoch 10/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 2.1030e-06 - val_accuracy: 1.0000 - val_loss: 3.7462e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 2.3736e-06 - val_accuracy: 1.0000 - val_loss: 3.4877e-07\n",
      "Epoch 12/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.7716e-06 - val_accuracy: 1.0000 - val_loss: 3.3010e-07\n",
      "Epoch 13/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 1.9638e-06 - val_accuracy: 1.0000 - val_loss: 3.0760e-07\n",
      "Epoch 14/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 1.6195e-06 - val_accuracy: 1.0000 - val_loss: 2.9467e-07\n",
      "Epoch 15/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 1.4767e-06 - val_accuracy: 1.0000 - val_loss: 2.7911e-07\n",
      "Epoch 16/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 2.0428e-06 - val_accuracy: 1.0000 - val_loss: 2.6690e-07\n",
      "Epoch 17/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.4949e-06 - val_accuracy: 1.0000 - val_loss: 2.5374e-07\n",
      "Epoch 18/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 1.3812e-06 - val_accuracy: 1.0000 - val_loss: 2.4105e-07\n",
      "Epoch 19/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.3680e-06 - val_accuracy: 1.0000 - val_loss: 2.3052e-07\n",
      "Epoch 20/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 1.1359e-06 - val_accuracy: 1.0000 - val_loss: 2.1879e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 1.1579e-06 - val_accuracy: 1.0000 - val_loss: 2.0921e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 1.3059e-06 - val_accuracy: 1.0000 - val_loss: 1.9725e-07\n",
      "Epoch 23/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 1.5390e-06 - val_accuracy: 1.0000 - val_loss: 1.8695e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 1.3708e-06 - val_accuracy: 1.0000 - val_loss: 1.7355e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.0138e-06 - val_accuracy: 1.0000 - val_loss: 1.6373e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 1.1590e-06 - val_accuracy: 1.0000 - val_loss: 1.5559e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 1.2768e-06 - val_accuracy: 1.0000 - val_loss: 1.4746e-07\n",
      "Epoch 28/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 1.0292e-06 - val_accuracy: 1.0000 - val_loss: 1.4075e-07\n",
      "Epoch 29/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 1.0504e-06 - val_accuracy: 1.0000 - val_loss: 1.3477e-07\n",
      "Epoch 30/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 7.2997e-07 - val_accuracy: 1.0000 - val_loss: 1.2759e-07\n",
      "Epoch 31/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 8.3155e-07 - val_accuracy: 1.0000 - val_loss: 1.1969e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 5.9833e-07 - val_accuracy: 1.0000 - val_loss: 1.1682e-07\n",
      "Epoch 33/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 1.2868e-06 - val_accuracy: 1.0000 - val_loss: 1.1322e-07\n",
      "Epoch 34/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 6.4953e-07 - val_accuracy: 1.0000 - val_loss: 1.0844e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 1.0050e-06 - val_accuracy: 1.0000 - val_loss: 1.0365e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 5.7429e-07 - val_accuracy: 1.0000 - val_loss: 9.7665e-08\n",
      "Epoch 37/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 6.6194e-07 - val_accuracy: 1.0000 - val_loss: 9.3357e-08\n",
      "Epoch 38/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 5.0733e-07 - val_accuracy: 1.0000 - val_loss: 9.0963e-08\n",
      "Epoch 39/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 7.4674e-07 - val_accuracy: 1.0000 - val_loss: 8.7851e-08\n",
      "Epoch 40/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 1.4023e-06 - val_accuracy: 1.0000 - val_loss: 8.1148e-08\n",
      "Epoch 41/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 6.5957e-07 - val_accuracy: 1.0000 - val_loss: 7.8755e-08\n",
      "Epoch 42/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 7.2001e-07 - val_accuracy: 1.0000 - val_loss: 7.3488e-08\n",
      "Epoch 43/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 5.4229e-07 - val_accuracy: 1.0000 - val_loss: 7.0377e-08\n",
      "Epoch 44/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 7.0150e-07 - val_accuracy: 1.0000 - val_loss: 6.7265e-08\n",
      "Epoch 45/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 5.2948e-07 - val_accuracy: 1.0000 - val_loss: 6.4871e-08\n",
      "Epoch 46/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 6.3915e-07 - val_accuracy: 1.0000 - val_loss: 6.1280e-08\n",
      "Epoch 47/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 4.8242e-07 - val_accuracy: 1.0000 - val_loss: 5.7211e-08\n",
      "Epoch 48/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 7.9092e-07 - val_accuracy: 1.0000 - val_loss: 5.3860e-08\n",
      "Epoch 49/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 3.9393e-07 - val_accuracy: 1.0000 - val_loss: 5.1466e-08\n",
      "Epoch 50/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 4.4232e-07 - val_accuracy: 1.0000 - val_loss: 4.7875e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Assuming train_data and label_data are already prepared\n",
    "x_train = np.array(train_data)  # Convert train_data to numpy array\n",
    "y_train = np.array(label_data)  # Convert label_data to numpy array\n",
    "\n",
    "# Now you can proceed with model training\n",
    "model.fit(x=x_train[:1000], y=y_train[:1000], batch_size=batch_size, verbose=1, epochs=epochs, validation_data=(x_train[1000:1498], y_train[1000:1498]))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('models.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    text = normalize_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Label predict:  0\n"
     ]
    }
   ],
   "source": [
    "text = \"tệ\"\n",
    "text = pre_process(text)\n",
    "\n",
    "maxtrix_embedding = np.expand_dims(comment_embedding(text), axis=0)\n",
    "maxtrix_embedding = np.expand_dims(maxtrix_embedding, axis=3)\n",
    "\n",
    "result = model.predict(maxtrix_embedding)\n",
    "result = np.argmax(result)\n",
    "print(\"Label predict: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
