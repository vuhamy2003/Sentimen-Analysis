{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nhập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/product_df.csv')\n",
    "df = df[['Star Rating', 'Comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gắn nhãn cho bộ dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment Sentiment\n",
      "0            4                      Điện thoại này dùng rất thích         2\n",
      "1            4                               sử dụng thấy cũng ok         2\n",
      "2            2                      Bảo hành ít quá, chỉ 12 tháng         0\n",
      "3            5                             Sản phẩm mượt, chạy êm         2\n",
      "4            3  Cho mình hỏi muốn khởi động lại máy hay tắt ng...         1\n"
     ]
    }
   ],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return '0'\n",
    "    elif rating == 3:\n",
    "        return '1'\n",
    "    elif rating in [4, 5]:\n",
    "        return '2'\n",
    "    else:\n",
    "        return '3'  # Nếu có xếp hạng nằm ngoài khoảng 1-5\n",
    "\n",
    "# Gắn nhãn cảm xúc cho mỗi đánh giá\n",
    "df['Sentiment'] = df['Star Rating'].apply(label_sentiment)\n",
    "\n",
    "# Hiển thị 5 hàng đầu tiên của dataframe với cột sentiment mới\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Rating    0\n",
      "Comment        0\n",
      "Sentiment      0\n",
      "dtype: int64\n",
      "Star Rating    0\n",
      "Comment        0\n",
      "Sentiment      0\n",
      "dtype: int64\n",
      "Các dòng dữ liệu trùng lặp trong cột 'Comment':\n",
      "      Star Rating                                   Comment Sentiment\n",
      "48              4                                   Rất tốt         2\n",
      "76              5                                    Rất ok         2\n",
      "107             2                             pin tụt nhanh         0\n",
      "135             5                              sản phẩm tốt         2\n",
      "173             2                             hao pin nhanh         0\n",
      "177             5                              sản phẩm tốt         2\n",
      "181             5                                    Rất ok         2\n",
      "183             5                              sản phẩm tốt         2\n",
      "192             5                               sản phẩm ok         2\n",
      "205             5                               máy dùng ok         2\n",
      "225             4                                       Tốt         2\n",
      "227             5                               sản phẩm ok         2\n",
      "237             5                               máy dùng ok         2\n",
      "250             5                              sản phẩm tốt         2\n",
      "426             4                              máy dùng tốt         2\n",
      "435             5                                   Rất tốt         2\n",
      "461             4                                       Tốt         2\n",
      "516             5                                       Tốt         2\n",
      "526             4                                       Tốt         2\n",
      "529             4                                    Tạm ổn         2\n",
      "547             5                              Sản phẩm tốt         2\n",
      "549             5                                  Cũng tốt         2\n",
      "568             4                                  Hài lòng         2\n",
      "570             5                          Máy dùng rất tốt         2\n",
      "592             5                                       Tốt         2\n",
      "647             5                                   Rất tốt         2\n",
      "683             5                                       Tốt         2\n",
      "744             5                                       Tốt         2\n",
      "976             5                          Máy dùng rất tốt         2\n",
      "982             4                                 Tuyệt vời         2\n",
      "1153            5                                      Tốt.         2\n",
      "1160            5                          Máy sử dụng tốt.         2\n",
      "1163            5                                      Tốt.         2\n",
      "1237            5                                 Khá được.         2\n",
      "1244            4                                     Được.         2\n",
      "1260            5                             Rất hài lòng.         2\n",
      "1271            4                     Hiện tại sử dụng tốt.         2\n",
      "1272            5                         Tôi rất hài lòng.         2\n",
      "1273            4  Sản phẩm được. Hợp túi tiền dùng tạm ổn.         2\n",
      "1280            5                             Rất hài lòng.         2\n",
      "1283            5                                     Được.         2\n",
      "1311            5                             Dùng rất tốt.         2\n",
      "1328            5                  Điện thoại dùng rất tốt.         2\n",
      "1338            4                             Sản phẩm tốt.         2\n",
      "1409            5                                     Được.         2\n",
      "1443            4                                 Dùng tốt.         2\n",
      "Shape after dropping duplicates: (1498, 3)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra và loại bỏ giá trị khuyết thiếu\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Comment'])\n",
    "# Kiểm tra và loại bỏ giá trị khuyết thiếu\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Comment'])\n",
    "# Kiểm tra và loại bỏ dữ liệu trùng lặp\n",
    "duplicate_comments = df[df.duplicated(['Comment'])]\n",
    "print(\"Các dòng dữ liệu trùng lặp trong cột 'Comment':\")\n",
    "print(duplicate_comments)\n",
    "df = df.drop_duplicates(['Comment'])\n",
    "print(\"Shape after dropping duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment Sentiment\n",
      "0            4                      điện thoại này dùng rất thích         2\n",
      "1            4                               sử dụng thấy cũng ok         2\n",
      "2            2                       bảo hành ít quá chỉ 12 tháng         0\n",
      "3            5                              sản phẩm mượt chạy êm         2\n",
      "4            3  cho mình hỏi muốn khởi động lại máy hay tắt ng...         1\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa và làm sạch văn bản\n",
    "def remove_special_characters(text):\n",
    "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ cái, số, và các dấu câu\n",
    "    return re.sub(r'[^a-zA-ZÀ-ỹà-ỹ0-9\\s]', '', text)\n",
    "\n",
    "def to_lowercase(text):\n",
    "    # Chuyển đổi văn bản về chữ thường\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_special_characters(text)\n",
    "    text = to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(normalize_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of reviews X\n",
    "X = df['Comment'].values.tolist()\n",
    "# Extract the labels y\n",
    "y = df['Sentiment'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tách từ, xây dựng bộ từ vựng và mã hóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xây dựng hàm token từ underthesea\n",
    "def tokenize_and_build_vocab_vietnamese(comment):\n",
    "    tokens = word_tokenize(comment, format=\"text\")\n",
    "    return tokens.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_and_build_vocab_vietnamese, token_pattern=None,\n",
    "                              max_features=5000, ngram_range=(1, 2), max_df=0.85, min_df=5)\n",
    "# Fit and transform the data\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mã hóa cho cột nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cân bằng dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước khi cân bằng: Counter({2: 832, 0: 428, 1: 238})\n",
      "Sau khi cân bằng: Counter({2: 832, 0: 832, 1: 832})\n"
     ]
    }
   ],
   "source": [
    "#Sử dụng SMOTE để cân bằng dữ liệu\n",
    "\n",
    "print('Trước khi cân bằng:', Counter(y))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "print('Sau khi cân bằng:', Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu ban đầu: (1498, 1200)\n",
      "Kích thước dữ liệu sau khi cân bằng: (2496, 1200)\n",
      "Trước khi cân bằng: Counter({2: 832, 0: 428, 1: 238})\n",
      "Sau khi cân bằng: Counter({2: 832, 0: 832, 1: 832})\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước dữ liệu ban đầu:', X_tfidf.shape)\n",
    "print('Kích thước dữ liệu sau khi cân bằng:', X_resampled.shape)\n",
    "# In ra số lượng mẫu của từng nhãn trước và sau khi cân bằng\n",
    "print('Trước khi cân bằng:', Counter(y))\n",
    "print('Sau khi cân bằng:', Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập huấn luyện và tập validation (validation + test)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
    "\n",
    "# Chia tập tạm thời thành tập validation và tập test cuối cùng\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng mô hình CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 128)          640000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 100, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 96, 128)           82048     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 755,843\n",
      "Trainable params: 755,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Parameters\n",
    "max_features = 5000  # Size of the vocabulary\n",
    "max_len = 100  # Maximum length of the sequences (comments)\n",
    "\n",
    "# Pad sequences to ensure they are of equal length\n",
    "X_train_padded = pad_sequences(X_train.toarray(), maxlen=max_len)\n",
    "X_val_padded = pad_sequences(X_val.toarray(), maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test.toarray(), maxlen=max_len)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "47/47 [==============================] - 5s 63ms/step - loss: 1.0997 - accuracy: 0.3407 - val_loss: 1.1032 - val_accuracy: 0.3200\n",
      "Epoch 2/15\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 1.1021 - accuracy: 0.3093 - val_loss: 1.0984 - val_accuracy: 0.3467\n",
      "Epoch 3/15\n",
      "47/47 [==============================] - 3s 57ms/step - loss: 1.0996 - accuracy: 0.3200 - val_loss: 1.0992 - val_accuracy: 0.3333\n",
      "Epoch 4/15\n",
      "47/47 [==============================] - 3s 55ms/step - loss: 1.0988 - accuracy: 0.3273 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 5/15\n",
      "47/47 [==============================] - 3s 54ms/step - loss: 1.0986 - accuracy: 0.3287 - val_loss: 1.0992 - val_accuracy: 0.3200\n",
      "Epoch 6/15\n",
      "47/47 [==============================] - 3s 65ms/step - loss: 1.0987 - accuracy: 0.3427 - val_loss: 1.0996 - val_accuracy: 0.3200\n",
      "Epoch 7/15\n",
      "47/47 [==============================] - 3s 66ms/step - loss: 1.0989 - accuracy: 0.3287 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 8/15\n",
      "47/47 [==============================] - 3s 64ms/step - loss: 1.0970 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 9/15\n",
      "47/47 [==============================] - 4s 83ms/step - loss: 1.0973 - accuracy: 0.3213 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 10/15\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 1.0969 - accuracy: 0.3280 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 11/15\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 1.0963 - accuracy: 0.3447 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 12/15\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 1.0973 - accuracy: 0.3066 - val_loss: 1.0989 - val_accuracy: 0.3333\n",
      "Epoch 13/15\n",
      "47/47 [==============================] - 3s 60ms/step - loss: 1.0968 - accuracy: 0.3380 - val_loss: 1.0988 - val_accuracy: 0.3333\n",
      "Epoch 14/15\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.0965 - accuracy: 0.3373 - val_loss: 1.0990 - val_accuracy: 0.3333\n",
      "Epoch 15/15\n",
      "47/47 [==============================] - 4s 75ms/step - loss: 1.0967 - accuracy: 0.3213 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 1.0969 - accuracy: 0.3285\n",
      "Test Accuracy: 0.3285256326198578\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_padded, y_train, epochs=15, batch_size=32, validation_data=(X_val_padded, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
