{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập dữ liệu\n",
    "df = pd.read_csv('./data/product_df.csv')\n",
    "df = df[['Star Rating', 'Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment Sentiment\n",
      "0            4                      Điện thoại này dùng rất thích         2\n",
      "1            4                               sử dụng thấy cũng ok         2\n",
      "2            2                      Bảo hành ít quá, chỉ 12 tháng         0\n",
      "3            5                             Sản phẩm mượt, chạy êm         2\n",
      "4            3  Cho mình hỏi muốn khởi động lại máy hay tắt ng...         1\n"
     ]
    }
   ],
   "source": [
    "def label_sentiment(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return '0'\n",
    "    elif rating == 3:\n",
    "        return '1'\n",
    "    elif rating in [4, 5]:\n",
    "        return '2'\n",
    "    else:\n",
    "        return '3'  # Nếu có xếp hạng nằm ngoài khoảng 1-5\n",
    "\n",
    "# Gắn nhãn cảm xúc cho mỗi đánh giá\n",
    "df['Sentiment'] = df['Star Rating'].apply(label_sentiment)\n",
    "\n",
    "# Hiển thị 5 hàng đầu tiên của dataframe với cột sentiment mới\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Rating    0\n",
      "Comment        0\n",
      "Sentiment      0\n",
      "dtype: int64\n",
      "Star Rating    0\n",
      "Comment        0\n",
      "Sentiment      0\n",
      "dtype: int64\n",
      "Các dòng dữ liệu trùng lặp trong cột 'Comment':\n",
      "      Star Rating                                   Comment Sentiment\n",
      "48              4                                   Rất tốt         2\n",
      "76              5                                    Rất ok         2\n",
      "107             2                             pin tụt nhanh         0\n",
      "135             5                              sản phẩm tốt         2\n",
      "173             2                             hao pin nhanh         0\n",
      "177             5                              sản phẩm tốt         2\n",
      "181             5                                    Rất ok         2\n",
      "183             5                              sản phẩm tốt         2\n",
      "192             5                               sản phẩm ok         2\n",
      "205             5                               máy dùng ok         2\n",
      "225             4                                       Tốt         2\n",
      "227             5                               sản phẩm ok         2\n",
      "237             5                               máy dùng ok         2\n",
      "250             5                              sản phẩm tốt         2\n",
      "426             4                              máy dùng tốt         2\n",
      "435             5                                   Rất tốt         2\n",
      "461             4                                       Tốt         2\n",
      "516             5                                       Tốt         2\n",
      "526             4                                       Tốt         2\n",
      "529             4                                    Tạm ổn         2\n",
      "547             5                              Sản phẩm tốt         2\n",
      "549             5                                  Cũng tốt         2\n",
      "568             4                                  Hài lòng         2\n",
      "570             5                          Máy dùng rất tốt         2\n",
      "592             5                                       Tốt         2\n",
      "647             5                                   Rất tốt         2\n",
      "683             5                                       Tốt         2\n",
      "744             5                                       Tốt         2\n",
      "976             5                          Máy dùng rất tốt         2\n",
      "982             4                                 Tuyệt vời         2\n",
      "1153            5                                      Tốt.         2\n",
      "1160            5                          Máy sử dụng tốt.         2\n",
      "1163            5                                      Tốt.         2\n",
      "1237            5                                 Khá được.         2\n",
      "1244            4                                     Được.         2\n",
      "1260            5                             Rất hài lòng.         2\n",
      "1271            4                     Hiện tại sử dụng tốt.         2\n",
      "1272            5                         Tôi rất hài lòng.         2\n",
      "1273            4  Sản phẩm được. Hợp túi tiền dùng tạm ổn.         2\n",
      "1280            5                             Rất hài lòng.         2\n",
      "1283            5                                     Được.         2\n",
      "1311            5                             Dùng rất tốt.         2\n",
      "1328            5                  Điện thoại dùng rất tốt.         2\n",
      "1338            4                             Sản phẩm tốt.         2\n",
      "1409            5                                     Được.         2\n",
      "1443            4                                 Dùng tốt.         2\n",
      "Shape after dropping duplicates: (1498, 3)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra và loại bỏ giá trị khuyết thiếu\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Comment'])\n",
    "# Kiểm tra và loại bỏ giá trị khuyết thiếu\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna(subset=['Comment'])\n",
    "# Kiểm tra và loại bỏ dữ liệu trùng lặp\n",
    "duplicate_comments = df[df.duplicated(['Comment'])]\n",
    "print(\"Các dòng dữ liệu trùng lặp trong cột 'Comment':\")\n",
    "print(duplicate_comments)\n",
    "df = df.drop_duplicates(['Comment'])\n",
    "print(\"Shape after dropping duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Star Rating                                            Comment Sentiment\n",
      "0            4                      điện thoại này dùng rất thích         2\n",
      "1            4                               sử dụng thấy cũng ok         2\n",
      "2            2                       bảo hành ít quá chỉ 12 tháng         0\n",
      "3            5                              sản phẩm mượt chạy êm         2\n",
      "4            3  cho mình hỏi muốn khởi động lại máy hay tắt ng...         1\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa và làm sạch văn bản\n",
    "def remove_special_characters(text):\n",
    "    # Loại bỏ các ký tự đặc biệt, giữ lại chữ cái, số, và các dấu câu\n",
    "    return re.sub(r'[^a-zA-ZÀ-ỹà-ỹ0-9\\s]', '', text)\n",
    "\n",
    "def to_lowercase(text):\n",
    "    # Chuyển đổi văn bản về chữ thường\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_special_characters(text)\n",
    "    text = to_lowercase(text)\n",
    "    return text\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(normalize_text)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu đánh giá vào cột X\n",
    "X = df['Comment'].values.tolist()\n",
    "# Lưu nhãn vào cột Y\n",
    "y = df['Sentiment'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xây dựng hàm token từ underthesea\n",
    "def tokenize_and_build_vocab_vietnamese(comment):\n",
    "    tokens = word_tokenize(comment, format=\"text\")\n",
    "    return tokens.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_and_build_vocab_vietnamese, token_pattern=None,\n",
    "                              max_features=5000, ngram_range=(1, 2), max_df=0.85, min_df=5)\n",
    "# Vectorize dữ liệu\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước khi cân bằng: Counter({2: 832, 0: 428, 1: 238})\n",
      "Sau khi cân bằng: Counter({2: 832, 0: 832, 1: 832})\n"
     ]
    }
   ],
   "source": [
    "#Sử dụng SMOTE để cân bằng dữ liệu\n",
    "\n",
    "print('Trước khi cân bằng:', Counter(y))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "print('Sau khi cân bằng:', Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước dữ liệu ban đầu: (1498, 1200)\n",
      "Kích thước dữ liệu sau khi cân bằng: (2496, 1200)\n",
      "Trước khi cân bằng: Counter({2: 832, 0: 428, 1: 238})\n",
      "Sau khi cân bằng: Counter({2: 832, 0: 832, 1: 832})\n"
     ]
    }
   ],
   "source": [
    "print('Kích thước dữ liệu ban đầu:', X_tfidf.shape)\n",
    "print('Kích thước dữ liệu sau khi cân bằng:', X_resampled.shape)\n",
    "# In ra số lượng mẫu của từng nhãn trước và sau khi cân bằng\n",
    "print('Trước khi cân bằng:', Counter(y))\n",
    "print('Sau khi cân bằng:', Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập huấn luyện và tập validation (validation + test)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
    "\n",
    "# Chia tập tạm thời thành tập validation và tập test cuối cùng\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo mô hình Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Định nghĩa các tham số để tinh chỉnh\n",
    "nb_params = {\n",
    "    'alpha': [0.1, 0.5, 1.0],\n",
    "    'fit_prior': [True, False],\n",
    "}\n",
    "\n",
    "# Tinh chỉnh hyperparameters bằng GridSearchCV\n",
    "nb_grid = GridSearchCV(estimator=nb_model, param_grid=nb_params, cv=3, scoring='accuracy')\n",
    "nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Lấy mô hình tốt nhất sau khi tinh chỉnh\n",
    "best_nb = nb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo mô hình SVM\n",
    "svm_model = SVC()\n",
    "\n",
    "# Định nghĩa các tham số để tinh chỉnh\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "}\n",
    "\n",
    "# Tinh chỉnh hyperparameters bằng GridSearchCV\n",
    "svm_grid = GridSearchCV(estimator=svm_model, param_grid=svm_params, cv=3, scoring='accuracy')\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Lấy mô hình tốt nhất sau khi tinh chỉnh\n",
    "best_svm = svm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vuhamy\\AppData\\Local\\Temp\\ipykernel_12604\\1867992275.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Hàm xây dựng mô hình cho GridSearch\n",
    "def create_model(neurons, dropout_rate, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(neurons // 2, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Xây dựng mô hình KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Tham số tìm kiếm GridSearch\n",
    "param_grid = {\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [5,10, 20, 30],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'neurons': [64, 128],\n",
    "    'dropout_rate': [0.2, 0.3]\n",
    "}\n",
    "\n",
    "# GridSearch\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Lấy mô hình tốt nhất sau khi tinh chỉnh\n",
    "best_dnn = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the classifiers with their best parameters\n",
    "nb_model = best_nb\n",
    "svm_model = best_svm\n",
    "dnn_model = best_dnn.model\n",
    "# Create a voting classifier with soft voting\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), ('svm', svm_model), ('dnn', dnn_model)],\n",
    "    voting='soft'  # Use 'soft' for probabilities\n",
    ")\n",
    "\n",
    "# Fit the voting classifier on the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = voting_classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_nb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Kết hợp các mô hình vào một Voting Classifier\u001b[39;00m\n\u001b[0;32m      4\u001b[0m voting_classifier \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m----> 5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, best_nb),  \u001b[38;5;66;03m# Naive Bayes đã tinh chỉnh\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m'\u001b[39m, best_svm),  \u001b[38;5;66;03m# SVM đã tinh chỉnh\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;124m'\u001b[39m, best_dnn)  \u001b[38;5;66;03m# DNN đã tinh chỉnh\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ], voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Sử dụng soft voting\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Huấn luyện mô hình kết hợp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m voting_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_nb' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Kết hợp các mô hình vào một Voting Classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('nb', best_nb),  # Naive Bayes đã tinh chỉnh\n",
    "    ('svm', best_svm),  # SVM đã tinh chỉnh\n",
    "    ('dnn', best_dnn)  # DNN đã tinh chỉnh\n",
    "], voting='soft')  # Sử dụng soft voting\n",
    "\n",
    "# Huấn luyện mô hình kết hợp\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Đánh giá mô hình kết hợp trên tập kiểm tra\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bao gồm comment mới vào một list\n",
    "new_comments = [\n",
    "    \"Sản phẩm tốt, rất hài lòng!\",\n",
    "    \"Pin yếu, cam tệ, màn hình giật lag liên tục\",\n",
    "    \"Chỉ sử dụng ở mức tạm ổn, tôi muốn pass lại\"\n",
    "]\n",
    "\n",
    "# Chuẩn hóa và làm sạch các comment mới\n",
    "cleaned_comments = [normalize_text(comment) for comment in new_comments]\n",
    "\n",
    "# Vectorize các comment mới bằng vectorizer đã huấn luyện\n",
    "X_new_tfidf = vectorizer.transform(cleaned_comments)\n",
    "\n",
    "# Dự đoán cảm xúc của các comment bằng mô hình kết hợp đã tinh chỉnh\n",
    "y_pred_new = voting_classifier.predict(X_new_tfidf)\n",
    "\n",
    "# Giải mã các nhãn dự đoán về các cảm xúc\n",
    "predicted_labels = label_encoder.inverse_transform(y_pred_new)\n",
    "\n",
    "# Hiển thị kết quả\n",
    "for comment, predicted_label in zip(new_comments, predicted_labels):\n",
    "    print(f'Comment: \"{comment}\"')\n",
    "    print(f'Predicted Sentiment: {predicted_label}')\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
